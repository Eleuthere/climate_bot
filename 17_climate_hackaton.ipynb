{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import feedparser\n",
    "import os, string\n",
    "import sys\n",
    "import tweepy, time\n",
    "from priv_access import * ## change `priv_access` to `access` with your API tokens\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "\n",
    "## list of the distribution\n",
    "# mylist_id = '1321018474639085578' #todo add covid example\n",
    "## list of user id to check\n",
    "# user_id=''\n",
    "## reosted error to ignore for the log.list\n",
    "IGNORE_ERRORS = [327]\n",
    "\n",
    "\n",
    "# Setup API:\n",
    "def twitter_setup():\n",
    "    # Authenticate and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API access:\n",
    "    api = tweepy.API(auth,parser=tweepy.parsers.JSONParser())\n",
    "    \n",
    "#     api = tweepy.API(auth,parser=tweepy.parsers.JSONParser())\n",
    "    return (api)\n",
    "\n",
    "\n",
    "class Settings:\n",
    "    \"\"\"Twitter bot application settings.\n",
    "\n",
    "    Enter the RSS feed you want to tweet, or keywords you want to retweet.\n",
    "    \"\"\"\n",
    "    # RSS feeds to read and post tweets from.\n",
    "    feed_urls = [\"https://pubmed.ncbi.nlm.nih.gov/rss/search/1Di1IZzM0R4FRnKYsI1qINYHDYUiWSVAWo0rd3bhufn34wQ9HU/?limit=100&utm_campaign=pubmed-2&fc=20201028084526\",\n",
    "     'http://export.arxiv.org/api/query?search_query=all:psilocybin*&start=0&max_results=100&sortBy=lastUpdatedDate&sortOrder=descending',\n",
    "        ]\n",
    "    # nested list/dictionary comprehension to parse multiple RSS feeds\n",
    "    combined_feed = [feedparser.parse(url) for url in feed_urls]    # Log file to save all tweeted RSS links (one URL per line).\n",
    "    posted_urls_output_file = \"posted-urls.log\"\n",
    "\n",
    "    # Log file to save all retweeted tweets (one tweetid per line).\n",
    "    posted_retweets_output_file = \"posted-retweets.log\"\n",
    "\n",
    "    # Include tweets with these words when retweeting.\n",
    "    retweet_include_words = [\"Drugpolicy\", \"regulatestimulants\", \"safeconsumption\"]\n",
    "\n",
    "    # Do not include tweets with these words when retweeting.\n",
    "    retweet_exclude_words = []\n",
    "\n",
    "\n",
    "def compose_message(item: feedparser.FeedParserDict) -> str:\n",
    "    \"\"\"Compose a tweet from an RSS item (title, link, description)\n",
    "    and return final tweet message.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    item: feedparser.FeedParserDict\n",
    "        An RSS item.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns a message suited for a Twitter status update.\n",
    "    \"\"\"\n",
    "    title = ' '.join(\n",
    "        [f\"#{x}\" if x.lower().translate(str.maketrans('', '', string.punctuation)) in add_hashtag else x for x in\n",
    "         item[\"title\"].split()])\n",
    "    link, _ = item[\"link\"], item[\"description\"]\n",
    "    message = shorten_text(title, maxlength=250) + \" \" + link\n",
    "    return message\n",
    "\n",
    "\n",
    "def shorten_text(text: str, maxlength: int) -> str:\n",
    "    \"\"\"Truncate text and append three dots (...) at the end if length exceeds\n",
    "    maxlength chars.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        The text you want to shorten.\n",
    "    maxlength: int\n",
    "        The maximum character length of the text string.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns a shortened text string.\n",
    "    \"\"\"\n",
    "    return (text[:maxlength] + '...') if len(text) > maxlength else text\n",
    "\n",
    "\n",
    "def post_tweet(message: str):\n",
    "    \"\"\"Post tweet message to account.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    message: str\n",
    "        Message to post on Twitter.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        twitter_api = twitter_setup()\n",
    "#         twitter_api.update_status(status=message)\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def read_rss_and_tweet(url: str):\n",
    "    \"\"\"Read RSS and post feed items as a tweet.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url: str\n",
    "        URL to RSS feed.\n",
    "    \"\"\"\n",
    "    feeds = Settings.combined_feed\n",
    "    count = 0\n",
    "    for feed in feeds:\n",
    "        if feed:\n",
    "            while count in range(0, len(feed[\"items\"])):\n",
    "                item = feed[\"items\"][count]\n",
    "                link = item[\"link\"]\n",
    "                link_id = item.id\n",
    "\n",
    "                if not is_in_logfile(link_id, Settings.posted_urls_output_file):\n",
    "    #                 post_tweet(message=compose_message(item))\n",
    "                    write_to_logfile(link_id, Settings.posted_urls_output_file)\n",
    "                    print(\"Posted:\", link_id, compose_message(item))\n",
    "                    break\n",
    "                else:\n",
    "                    print(count, \"Already posted:\", link_id, \"Trying next\")\n",
    "                    count += 1\n",
    "        else:\n",
    "            print(\"Nothing found in feed\", url)\n",
    "\n",
    "\n",
    "def get_query() -> str:\n",
    "    \"\"\"Create Twitter search query with included words minus the\n",
    "    excluded words.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns a string with the Twitter search query.\n",
    "    \"\"\"\n",
    "    include = \" OR \".join(Settings.retweet_include_words)\n",
    "    exclude = \" -\".join(Settings.retweet_exclude_words)\n",
    "    exclude = \"-\" + exclude if exclude else \"\"\n",
    "    return include + \" \" + exclude\n",
    "\n",
    "\n",
    "def try_retweet(twitter_api, tweet_text, tweet_id):\n",
    "    \n",
    "    '''try to retweet, if already retweeted try next fom the list\n",
    "    of recent tweets'''\n",
    "\n",
    "    if not is_in_logfile(\n",
    "            tweet_id, Settings.posted_retweets_output_file):\n",
    "        try:\n",
    "#             twitter_api.retweet(id=tweet_id)\n",
    "            write_to_logfile(\n",
    "                tweet_id, Settings.posted_retweets_output_file)\n",
    "            print(\"Retweeted {} (id {})\".format(shorten_text(\n",
    "                tweet_text, maxlength=140), tweet_id))\n",
    "            return True\n",
    "        except tweepy.TweepError as e:\n",
    "            if e.api_code in IGNORE_ERRORS:\n",
    "                return False\n",
    "            else:\n",
    "                print(e)\n",
    "                return True\n",
    "    else:\n",
    "        print(\"Already retweeted {} (id {})\".format(\n",
    "            shorten_text(tweet_text, maxlength=140), tweet_id))\n",
    "\n",
    "\n",
    "def search_and_retweet(flag='global_search', count=10):\n",
    "    \"\"\"Search for a query in tweets, and retweet those tweets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flag: str\n",
    "        A query to search for on Twitter. it can be `global_search` to search globally\n",
    "        or `list_search` reduced to a list defined on mylist_id\n",
    "    count: int\n",
    "        Number of tweets to search for. You should probably keep this low\n",
    "        when you use search_and_retweet() on a schedule (e.g. cronjob).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        twitter_api = twitter_setup()\n",
    "        #         search_results = twitter_api.search(q=query, count=count)\n",
    "        if flag == 'global_search':\n",
    "            ## search results retweets globally forgiven keywords\n",
    "            search_results = twitter_api.search(q=get_query(), count=count)  ## standard search results\n",
    "        else:\n",
    "            ## search list retwwets most commented ad rt from the experts lists\n",
    "            search_results = twitter_api.list_timeline(list_id=mylist_id)  ## list to tweet from\n",
    "\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e.reason)\n",
    "        return\n",
    "\n",
    "    # Make sure we don't retweet any dubplicates.\n",
    "    count = 0\n",
    "    ## get the most faved+ rtweeted and retweet it\n",
    "    max_val = sorted(([(x.retweet_count, x.id_str, x.text) for x in search_results]))\n",
    "\n",
    "    while (True):\n",
    "        tweet_id = max_val[-1 - count][1]\n",
    "        tweet_text = max_val[-1 - count][2]\n",
    "        if try_retweet(twitter_api, tweet_text, tweet_id):\n",
    "            break\n",
    "        elif count > len(search_results):\n",
    "            print('no more tweets to publish')\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "\n",
    "def is_in_logfile(content: str, filename: str) -> bool:\n",
    "    \"\"\"Does the content exist on any line in the log file?\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content: str\n",
    "        Content to search file for.\n",
    "    filename: str\n",
    "        Full path to file to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Returns `True` if content is found in file, otherwise `False`.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            lines = f.readlines()\n",
    "        if (content + \"\\n\" or content) in lines:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def retweet_own():\n",
    "    \"\"\"\n",
    "    re-tweet self last tweetet message.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    try:\n",
    "        while True:\n",
    "            twitter_api = twitter_setup()\n",
    "            tweet = twitter_api.user_timeline(id=twitter_api, count=10)[count]\n",
    "            if not tweet.retweeted:\n",
    "#                 twitter_api.retweet(tweet.id_str)\n",
    "                print(\"retweeted: \", tweet.text)\n",
    "                break\n",
    "            else:\n",
    "                print('already retweeted, trying next')\n",
    "                count += 1\n",
    "\n",
    "    except tweepy.TweepError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def write_to_logfile(content: str, filename: str):\n",
    "    \"\"\"Append content to log file, on one line.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    content: str\n",
    "        Content to append to file.\n",
    "    filename: str\n",
    "        Full path to file that should be appended.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"a\") as f:\n",
    "            f.write(content + \"\\n\")\n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "    while 1:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "def display_help():\n",
    "    \"\"\"Show available commands.\"\"\"\n",
    "    print(\"Syntax: python {} [command]\".format(sys.argv[0]))\n",
    "    print()\n",
    "    print(\" Commands:\")\n",
    "    print(\"    rss    Read URL and post new items to Twitter\")\n",
    "    print(\"    rtg    Search and retweet keywords from global feed\")\n",
    "    print(\"    rtl    Search and retweet keywords from list feed\")\n",
    "    print(\"    rto    Retweet last own tweet\")\n",
    "    print(\"    help   Show this help screen\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) > 1:\n",
    "        if sys.argv[1].lower() == \"rss\":\n",
    "            read_rss_and_tweet(url=Settings.combined_feed)\n",
    "        elif sys.argv[1].lower() == \"rtg\":\n",
    "            search_and_retweet('global_search')\n",
    "        elif sys.argv[1].lower() == \"rtl\":\n",
    "            search_and_retweet('list_search')\n",
    "        elif sys.argv[1].lower() == \"rto\":\n",
    "            retweet_own()\n",
    "        else:\n",
    "            display_help()\n",
    "    else:\n",
    "        display_help()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb.cursors\n",
    "import pandas as pd\n",
    "\n",
    "twitter_handles=pd.read_csv('TwitterHandles.csv')\n",
    "display(twitter_handles.head())\n",
    "## database connection\n",
    "db = MySQLdb.connect(host='',\n",
    "                               user='hackathon',\n",
    "                               port=(3306),\n",
    "                               password='',\n",
    "                               database='')\n",
    "\n",
    "c = db.cursor()\n",
    "\n",
    "def fill_database(user):\n",
    "\n",
    "    # IPCC_CH\n",
    "    # drug_papers\n",
    "    # GretaThunberg\n",
    "\n",
    "    tables_list=['new_retweet', 'new_tweet', 'new_user']\n",
    "\n",
    "\n",
    "\n",
    "    api=twitter_setup()\n",
    "    tweets = api.user_timeline(screen_name=user, \n",
    "                               # 200 is the maximum allowed count\n",
    "                               count=200,\n",
    "                               include_rts = True,\n",
    "                               # Necessary to keep full_text \n",
    "                               # otherwise only the first 140 words are extracted\n",
    "                               tweet_mode = 'extended'\n",
    "                               )\n",
    "    user_data = api.get_user(user) \n",
    "    \n",
    "    created_at=user_data['created_at']\n",
    "    print(created_at)\n",
    "    user_id=user_data['id']\n",
    "\n",
    "\n",
    "    tables_dic={}\n",
    "#     dictionary for the columns insert statement \n",
    "    for table in tables_list:\n",
    "        sql = f\"DESCRIBE {table};\"\n",
    "        c.execute(sql)\n",
    "        fetch_cols = c.fetchall()\n",
    "        ## keep columns that are in the MySQL table\n",
    "        column_names = [x[0] for x in fetch_cols]\n",
    "\n",
    "        cols = \",\".join([str(i) for i in column_names])\n",
    "        tables_dic[table]=cols\n",
    "\n",
    "    insert_vals=(user_id, user,'',created_at)\n",
    "    sql = f'INSERT IGNORE INTO new_user ({tables_dic[\"new_user\"]}) VALUES (%s,%s,\"%s\",%s);'\n",
    "    # print((sql%insert_vals))\n",
    "#     c.execute(sql,insert_vals)\n",
    "\n",
    "    for tweet in tweets:\n",
    "        \n",
    "        ## tweet variables\n",
    "        created_at=tweet['created_at']\n",
    "        tweet_id=tweet['id']  ## tweet_id\n",
    "#         is_rt=tweet['retweeted'] ### does not work, gotta check why but \n",
    "        if 'retweeted_status' in tweet:  ## but this works!\n",
    "            is_rt=True\n",
    "        else: is_rt=False\n",
    "            \n",
    "        tweet_text=tweet['full_text']  ## message of the tweet\n",
    "\n",
    "\n",
    "        \n",
    "        ## user variables\n",
    "        user_id=tweet['user']['id']\n",
    "#         created_at = user_id.created_at\n",
    "\n",
    "        if 'media' in tweet['entities']:\n",
    "            tweet_url=(tweet['entities']['media'][0]['url'])\n",
    "        else:\n",
    "            tweet_url=''\n",
    "\n",
    "\n",
    "        ## table tweet#############################\n",
    "#         print(created_at)\n",
    "        insert_vals_sql_tweet=(tweet_id,tweet_text,user_id,created_at,tweet_url,is_rt,user)\n",
    "        sql_tweet = f'INSERT IGNORE INTO new_tweet ({tables_dic[\"new_tweet\"]}) VALUES (%s,\"%s\",%s,\"%s\",\"%s\",%s,%s);'\n",
    "\n",
    "#         print(sql_tweet% insert_vals_sql_tweet)\n",
    "        c.execute(sql_tweet,insert_vals_sql_tweet)\n",
    "\n",
    "#         if is_rt == 1:\n",
    "\n",
    "        if 'retweeted_status' in tweet:\n",
    "\n",
    "            original_author=tweet['retweeted_status']['user']['id_str']\n",
    "            retweeted__id=tweet['retweeted_status']['id_str']\n",
    "#         else:\n",
    "#             original_author=user_id\n",
    "#             retweeted__id='?'\n",
    "\n",
    "            insert_vals_rt=(tweet_id, 0, user_id, original_author)\n",
    "            sql_retweet = f'INSERT IGNORE INTO new_retweet ({tables_dic[\"new_retweet\"]}) VALUES (%s, %s,%s,%s);'\n",
    "    #         print(sql% insert_vals_rt)\n",
    "#             c.execute(sql_retweet,insert_vals_rt)\n",
    "\n",
    "\n",
    "\n",
    "    db.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill in that db!!\n",
    "print(tweet['entities'])\n",
    "\n",
    "count=0\n",
    "\n",
    "for i, row in twitter_handles.iterrows():\n",
    "    count+=1\n",
    "    import_user=(row[1][1:])\n",
    "    print(import_user)\n",
    "    fill_database(import_user)\n",
    "#     if count == 3: break\n",
    "        \n",
    "        \n",
    "## for later \n",
    "# import datetime\n",
    "\n",
    "# date_time_str = 'Mon Jul 27 12:47:02 +0000 2009'\n",
    "# date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%b-%d %H:%M:%S.%f')\n",
    "\n",
    "# date_time_str = 'Jun 28 2018 7:40AM'\n",
    "# date_time_obj = datetime.datetime.strptime(date_time_str, '%b %d %Y %I:%M%p')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreply Bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "5\n",
      "5\n",
      "('aachsooo', '@isthisanexpert')\n",
      "('aachsooo', '@isthisanexpert')\n",
      "5\n",
      "aachsooo BBCWorld 5\n",
      "@aachsooo no way that is an expert!,do not trust that account!! @BBCWorld has a score of 5 in our database to learn more visit bit.ly/test\n",
      "aachsooo BBCWorld 5\n",
      "5\n",
      "5\n",
      "420\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "403\n",
      "5\n",
      "420\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "('JeanMarieFaliss', '@isthisanexpert')\n",
      "('JeanMarieFaliss', '@isthisanexpert')\n",
      "5\n",
      "('OP13325050', '@isthisanexpert')\n",
      "('OP13325050', '@isthisanexpert')\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "420\n",
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7dca11ad04c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mauto_replies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hold_that_tweet.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv, time\n",
    "import tweepy\n",
    "import json,ast\n",
    "from access_t import * ## change `priv_access` to `access` with your API tokens\n",
    "import subprocess\n",
    "\n",
    "IGNORE_ERRORS = [327]\n",
    "\n",
    "# Setup API:\n",
    "def twitter_setup():\n",
    "    # Authenticate and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    # Return API access:\n",
    "    api = tweepy.API(auth,parser=tweepy.parsers.JSONParser())\n",
    "    return (api)\n",
    "\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        # Decode the JSON data\n",
    "        tweet = json.loads(data)\n",
    "        # Print out the Tweet\n",
    "        print((tweet['user']['screen_name'], tweet['text']))\n",
    "\n",
    "        with open('hold_that_tweet.csv','a') as f:\n",
    "                f.write(data)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "        \n",
    "        \n",
    "api=twitter_setup()\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     listener = PrintListener()\n",
    "\n",
    "# Using readlines() \n",
    "\n",
    "# count = 0\n",
    "# Strips the newline character \n",
    "\n",
    "def auto_replies(twit_log_file):\n",
    "    file1 = open(twit_log_file, 'r') \n",
    "    Lines = file1.readlines() \n",
    "    \n",
    "    ## add for Paul's tool\n",
    "    proc = subprocess.Popen(['echo', '5'], stdout=subprocess.PIPE)\n",
    "    score = int(proc.stdout.read().decode(\"utf-8\"))\n",
    "    print(score)\n",
    "\n",
    "    for line in Lines: \n",
    "        tweet=(json.loads(line)) \n",
    "        if not 'quoted_status' in tweet:\n",
    "            continue\n",
    "        replied_to=(tweet['quoted_status']['user']['screen_name'])\n",
    "        answer_user=(tweet['user']['screen_name'])\n",
    "        answer_id=tweet['id']\n",
    "        \n",
    "        print(answer_user,replied_to,score)\n",
    "\n",
    "        # set the scores here\n",
    "        if score <= 5:\n",
    "            update_status=f'@{answer_user} no way that is an expert!,do not trust that account!! @{replied_to} has a score of {score} in our database to learn more visit bit.ly/test'\n",
    "\n",
    "        elif score > 5:\n",
    "            update_status=f'@{answer_user} be cautious!, this is a neutral! @{replied_to} has a score of {score} in our database to learn more visit bit.ly/test'\n",
    "\n",
    "        else:\n",
    "            update_status=f'@{answer_user} this is an expert you can trust!\\n@{replied_to} has a score of {score} in our database to learn more visit bit.ly/test'   \n",
    "        try:\n",
    "\n",
    "            api.update_status(update_status,answer_id)\n",
    "            print(update_status)\n",
    "\n",
    "        except tweepy.TweepError as e:\n",
    "            continue\n",
    "\n",
    "myStream.filter(track=['@isthisanexpert'], is_async=True)\n",
    "\n",
    "while 1:\n",
    "    try:\n",
    "        time.sleep(3)\n",
    "        auto_replies('hold_that_tweet.csv')\n",
    "        time.sleep(10)\n",
    "        file = open('hold_that_tweet.csv','r+')\n",
    "        file.truncate(0)\n",
    "        file.close()\n",
    "    except tweepy.TweepError as e:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "403\n",
      "403\n",
      "403\n",
      "('ySanseacabo', '@poertner_hans @IsThisAnExpert')('ySanseacabo', '@poertner_hans @IsThisAnExpert')\n",
      "\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "update_status=\"\"\"@{0} this is an expert you can trust!\n",
    "@{1} has a score of {2}in our database.\n",
    "to learn more visit bit.ly/test\"\"\".format('answer_user','replied_to',\"$SCORE\")\n",
    "\n",
    "\n",
    "\n",
    "update_status\n",
    "\n",
    "# file = open('hold_that_tweet.csv','r+')\n",
    "# file.truncate(0)\n",
    "# file.close()\n",
    "\n",
    "myStream.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(test_id)\n",
    "\n",
    "api.update_status(f'{\"@IsThisAnExpert0\"} this is an expert you can trust!\\n{\"$NAME\"} has a score of {\"$SCORE\"}in our database\\nto learn more visit bit.ly/awesomebot',\n",
    "                  1322702628967616512\n",
    "                 )\n",
    "# api.update_status('@ySanseacabo this is an expert you can trust!\\n{} has a score of X in our database\\nto learn more visit bit.ly/awesomebot',\n",
    "#                   '1322645929967702018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "api=twitter_setup()\n",
    "tweets = api.user_timeline(screen_name=user, \n",
    "                           # 200 is the maximum allowed count\n",
    "                           count=200,\n",
    "                           include_rts = True,\n",
    "                           # Necessary to keep full_text \n",
    "                           # otherwise only the first 140 words are extracted\n",
    "                           tweet_mode = 'extended'\n",
    "                           )\n",
    "user_data = api.get_user('ernafies') \n",
    "\n",
    "for tweet in tweets:\n",
    "    if 'retweeted_status' in tweet:\n",
    "        print(type(tweet['created_at']))\n",
    "        print(tweet)\n",
    "        print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('1322458847273979905')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_and_retweet('global_search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read_rss_and_tweet(url=Settings.feed_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
